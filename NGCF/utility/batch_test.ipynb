{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "batch_test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8S2rFvXJPdfo"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Created on Oct 10, 2018\n",
        "Tensorflow Implementation of Neural Graph Collaborative Filtering (NGCF) model in:\n",
        "Wang Xiang et al. Neural Graph Collaborative Filtering. In SIGIR 2019.\n",
        "\n",
        "@author: Xiang Wang (xiangwang@u.nus.edu)\n",
        "'''\n",
        "import utility.metrics as metrics\n",
        "from utility.parser import parse_args\n",
        "from utility.load_data import *\n",
        "import multiprocessing\n",
        "import heapq\n",
        "\n",
        "cores = multiprocessing.cpu_count() // 2\n",
        "\n",
        "args = parse_args()\n",
        "Ks = eval(args.Ks)\n",
        "\n",
        "data_generator = Data(path=args.data_path + args.dataset, batch_size=args.batch_size)\n",
        "USR_NUM, ITEM_NUM = data_generator.n_users, data_generator.n_items\n",
        "N_TRAIN, N_TEST = data_generator.n_train, data_generator.n_test\n",
        "BATCH_SIZE = args.batch_size\n",
        "\n",
        "def ranklist_by_heapq(user_pos_test, test_items, rating, Ks):\n",
        "    item_score = {}\n",
        "    for i in test_items:\n",
        "        item_score[i] = rating[i]\n",
        "\n",
        "    K_max = max(Ks)\n",
        "    K_max_item_score = heapq.nlargest(K_max, item_score, key=item_score.get)\n",
        "\n",
        "    r = []\n",
        "    for i in K_max_item_score:\n",
        "        if i in user_pos_test:\n",
        "            r.append(1)\n",
        "        else:\n",
        "            r.append(0)\n",
        "    auc = 0.\n",
        "    return r, auc\n",
        "\n",
        "def get_auc(item_score, user_pos_test):\n",
        "    item_score = sorted(item_score.items(), key=lambda kv: kv[1])\n",
        "    item_score.reverse()\n",
        "    item_sort = [x[0] for x in item_score]\n",
        "    posterior = [x[1] for x in item_score]\n",
        "\n",
        "    r = []\n",
        "    for i in item_sort:\n",
        "        if i in user_pos_test:\n",
        "            r.append(1)\n",
        "        else:\n",
        "            r.append(0)\n",
        "    auc = metrics.auc(ground_truth=r, prediction=posterior)\n",
        "    return auc\n",
        "\n",
        "def ranklist_by_sorted(user_pos_test, test_items, rating, Ks):\n",
        "    item_score = {}\n",
        "    for i in test_items:\n",
        "        item_score[i] = rating[i]\n",
        "\n",
        "    K_max = max(Ks)\n",
        "    K_max_item_score = heapq.nlargest(K_max, item_score, key=item_score.get)\n",
        "\n",
        "    r = []\n",
        "    for i in K_max_item_score:\n",
        "        if i in user_pos_test:\n",
        "            r.append(1)\n",
        "        else:\n",
        "            r.append(0)\n",
        "    auc = get_auc(item_score, user_pos_test)\n",
        "    return r, auc\n",
        "\n",
        "def get_performance(user_pos_test, r, auc, Ks):\n",
        "    precision, recall, ndcg, hit_ratio = [], [], [], []\n",
        "\n",
        "    for K in Ks:\n",
        "        precision.append(metrics.precision_at_k(r, K))\n",
        "        recall.append(metrics.recall_at_k(r, K, len(user_pos_test)))\n",
        "        ndcg.append(metrics.ndcg_at_k(r, K))\n",
        "        hit_ratio.append(metrics.hit_at_k(r, K))\n",
        "\n",
        "    return {'recall': np.array(recall), 'precision': np.array(precision),\n",
        "            'ndcg': np.array(ndcg), 'hit_ratio': np.array(hit_ratio), 'auc': auc}\n",
        "\n",
        "\n",
        "def test_one_user(x):\n",
        "    # user u's ratings for user u\n",
        "    rating = x[0]\n",
        "    #uid\n",
        "    u = x[1]\n",
        "    #user u's items in the training set\n",
        "    try:\n",
        "        training_items = data_generator.train_items[u]\n",
        "    except Exception:\n",
        "        training_items = []\n",
        "    #user u's items in the test set\n",
        "    user_pos_test = data_generator.test_set[u]\n",
        "\n",
        "    all_items = set(range(ITEM_NUM))\n",
        "\n",
        "    test_items = list(all_items - set(training_items))\n",
        "\n",
        "    if args.test_flag == 'part':\n",
        "        r, auc = ranklist_by_heapq(user_pos_test, test_items, rating, Ks)\n",
        "    else:\n",
        "        r, auc = ranklist_by_sorted(user_pos_test, test_items, rating, Ks)\n",
        "\n",
        "    return get_performance(user_pos_test, r, auc, Ks)\n",
        "\n",
        "\n",
        "def test(sess, model, users_to_test, drop_flag=False, batch_test_flag=False):\n",
        "    result = {'precision': np.zeros(len(Ks)), 'recall': np.zeros(len(Ks)), 'ndcg': np.zeros(len(Ks)),\n",
        "              'hit_ratio': np.zeros(len(Ks)), 'auc': 0.}\n",
        "\n",
        "    pool = multiprocessing.Pool(cores)\n",
        "\n",
        "    u_batch_size = BATCH_SIZE * 2\n",
        "    i_batch_size = BATCH_SIZE\n",
        "\n",
        "    test_users = users_to_test\n",
        "    n_test_users = len(test_users)\n",
        "    n_user_batchs = n_test_users // u_batch_size + 1\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    for u_batch_id in range(n_user_batchs):\n",
        "        start = u_batch_id * u_batch_size\n",
        "        end = (u_batch_id + 1) * u_batch_size\n",
        "\n",
        "        user_batch = test_users[start: end]\n",
        "\n",
        "        if batch_test_flag:\n",
        "\n",
        "            n_item_batchs = ITEM_NUM // i_batch_size + 1\n",
        "            rate_batch = np.zeros(shape=(len(user_batch), ITEM_NUM))\n",
        "\n",
        "            i_count = 0\n",
        "            for i_batch_id in range(n_item_batchs):\n",
        "                i_start = i_batch_id * i_batch_size\n",
        "                i_end = min((i_batch_id + 1) * i_batch_size, ITEM_NUM)\n",
        "\n",
        "                item_batch = range(i_start, i_end)\n",
        "\n",
        "                if drop_flag == False:\n",
        "                    i_rate_batch = sess.run(model.batch_ratings, {model.users: user_batch,\n",
        "                                                                model.pos_items: item_batch})\n",
        "                else:\n",
        "                    i_rate_batch = sess.run(model.batch_ratings, {model.users: user_batch,\n",
        "                                                                model.pos_items: item_batch,\n",
        "                                                                model.node_dropout: [0.]*len(eval(args.layer_size)),\n",
        "                                                                model.mess_dropout: [0.]*len(eval(args.layer_size))})\n",
        "                rate_batch[:, i_start: i_end] = i_rate_batch\n",
        "                i_count += i_rate_batch.shape[1]\n",
        "\n",
        "            assert i_count == ITEM_NUM\n",
        "\n",
        "        else:\n",
        "            item_batch = range(ITEM_NUM)\n",
        "\n",
        "            if drop_flag == False:\n",
        "                rate_batch = sess.run(model.batch_ratings, {model.users: user_batch,\n",
        "                                                              model.pos_items: item_batch})\n",
        "            else:\n",
        "                rate_batch = sess.run(model.batch_ratings, {model.users: user_batch,\n",
        "                                                              model.pos_items: item_batch,\n",
        "                                                              model.node_dropout: [0.] * len(eval(args.layer_size)),\n",
        "                                                              model.mess_dropout: [0.] * len(eval(args.layer_size))})\n",
        "\n",
        "        user_batch_rating_uid = zip(rate_batch, user_batch)\n",
        "        batch_result = pool.map(test_one_user, user_batch_rating_uid)\n",
        "        count += len(batch_result)\n",
        "\n",
        "        for re in batch_result:\n",
        "            result['precision'] += re['precision']/n_test_users\n",
        "            result['recall'] += re['recall']/n_test_users\n",
        "            result['ndcg'] += re['ndcg']/n_test_users\n",
        "            result['hit_ratio'] += re['hit_ratio']/n_test_users\n",
        "            result['auc'] += re['auc']/n_test_users\n",
        "\n",
        "\n",
        "    assert count == n_test_users\n",
        "    pool.close()\n",
        "    return result"
      ]
    }
  ]
}